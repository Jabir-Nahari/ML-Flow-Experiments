{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6df113a",
   "metadata": {},
   "source": [
    "### **Detailed Implementation Plan: MLflow Evaluation (3 Students)**\n",
    "\n",
    "This notebook documents the implementation plan, phases, and responsibilities for a team working on an MLflow evaluation project. Each section corresponds to one person and their responsibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f2bf2",
   "metadata": {},
   "source": [
    "### Jabir Nahari - Core Infrastructure & Basic Tracking\n",
    "\n",
    "#### **Phase 1: Foundation Setup**\n",
    "\n",
    "1. **Environment Configuration**\n",
    "\n",
    "- Set up MLflow tracking server locally\n",
    "\n",
    "1. **Dataset & Baseline Model**\n",
    "\n",
    "- Prepare datasets\n",
    "- Create baseline Random Forest and Logistic Regression models\n",
    "\n",
    "3. **Basic MLflow Integration**\n",
    "\n",
    "- Implement parameter logging for different algorithms\n",
    "- Set up metric tracking (accuracy, precision, recall, F1)\n",
    "- Create basic experiment run templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b61415d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:05 INFO mlflow.tracking.fluent: Experiment with name 'iris experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seeds for robustness testing: [5162, 4445, 9689, 2628, 4610]\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run adorable-seal-739 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/224a5ac333254e5e8839829de86c45fd\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/11 16:53:06 INFO mlflow.tracking.fluent: Experiment with name 'titanic experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run orderly-mole-818 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/7bb093ec4cbd4fd38e7210d1f2d3211a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run dashing-rat-866 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/1f8ba8ca3f1a450590e1a308bec38248\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run bold-ant-375 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/0cca3ed88ddc44028d379a90e5d03740\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run orderly-boar-314 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/98b2db60cba44c9da296e209c556004a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run stately-bee-691 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/3fa89323049140f091a0e78c773403e3\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:08 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run able-donkey-141 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/4963b8a781974290941a688182c2ea00\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run angry-crane-880 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/06c7395ddaa144199b0ce5d16f8eb9fb\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run intelligent-hawk-534 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/acbcc4ad931e45e986549c9f17842b75\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run charming-snake-894 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/36fa72455beb4c878152ac316c4d9eac\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run mysterious-stag-890 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/c22658638bf04b39912d72b78bf507e9\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run industrious-gull-648 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/0ca59ce01c734795a6035bf757a0971b\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run popular-crab-410 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/b049f4919497429c8317d6c8164107ff\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run enchanting-shad-734 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/6e82596a1c0b41aeb953d911f8dca5c0\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run nervous-yak-358 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/2ef89a4e8e5e491494436e0cd2ace700\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run honorable-hen-797 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/70cf0120c8934ab8802a277ab76eb6f4\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run casual-eel-246 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/90bb10219efc411cb12047077968a84f\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run merciful-bird-447 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/376c95295b2342b783491c410824e5ac\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run carefree-rook-403 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/7c3c15d912d843dc8ff2d45316382f99\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run victorious-hen-350 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/46ba17a86e904214a40505d1abbd9cfc\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "# Imports with checks\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"pandas is required for this notebook. Install with: pip install pandas\") from e\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "try:\n",
    "    import seaborn as sns\n",
    "except ImportError as e:\n",
    "    raise ImportError(\"Seaborn is required to load the Titanic dataset.\") from e\n",
    "\n",
    "# Loading and preprocessing datasets\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic = titanic.dropna(subset=['survived'])\n",
    "titanic = titanic.select_dtypes(include=['number']).fillna(0)\n",
    "if 'survived' not in titanic.columns:\n",
    "    raise RuntimeError('Titanic dataset does not contain the required \"survived\" column; ensure the dataset is available and correct')\n",
    "X_titanic = titanic.drop(columns=['survived'])\n",
    "y_titanic = titanic['survived']\n",
    "\n",
    "iris = load_iris(as_frame=True)\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# training and loggin all in one function\n",
    "def train_and_log_baselines(X, y, dataset_name='dataset', seed=42):\n",
    "    import mlflow\n",
    "    from mlflow.models.signature import infer_signature\n",
    "    import numpy as np\n",
    "    \n",
    "    TRACKING_URI = 'http://127.0.0.1:5000'\n",
    "    mlflow.set_tracking_uri(TRACKING_URI)\n",
    "    print('MLflow tracking URI ->', mlflow.get_tracking_uri())\n",
    "\n",
    "    experiment_name = f\"{dataset_name} experiment\"\n",
    "    try:\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        print(f'Warning: could not set experiment \"{experiment_name}\": {e}')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    models = {\n",
    "        'random_forest': RandomForestClassifier(random_state=seed),\n",
    "        'logistic_regression': LogisticRegression(max_iter=500)\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.log_param('model', name)\n",
    "            mlflow.log_param('dataset', dataset_name)\n",
    "            mlflow.log_param('seed', seed)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            mlflow.log_metrics({'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1})\n",
    "            try:\n",
    "                try:\n",
    "                    input_example = X_train.head(5)\n",
    "                except Exception:\n",
    "                    input_example = pd.DataFrame(np.array(X_train)[:5])\n",
    "                try:\n",
    "                    sample_X = input_example\n",
    "                    sample_preds = model.predict(sample_X)\n",
    "                    signature = infer_signature(sample_X, sample_preds)\n",
    "                except Exception:\n",
    "                    signature = None\n",
    "                import mlflow.sklearn\n",
    "                try:\n",
    "                    mlflow.sklearn.log_model(model, name='./artifacts/', signature=signature, input_example=input_example)\n",
    "                except TypeError:\n",
    "                    try:\n",
    "                        mlflow.sklearn.log_model(model, artifact_path='./artifacts/', signature=signature, input_example=input_example)\n",
    "                    except Exception:\n",
    "                        raise\n",
    "            except Exception:\n",
    "                try:\n",
    "                    import mlflow.sklearn\n",
    "                    mlflow.sklearn.log_model(model, artifact_path='./artifacts/')\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "# Generate a list of random seeds for robustness testing\n",
    "seeds = [random.randint(0, 10000) for _ in range(5)]\n",
    "print(f'Using seeds for robustness testing: {seeds}')\n",
    "\n",
    "# Train and log for Iris and Titanic datasets across seeds\n",
    "for seed in seeds:\n",
    "    train_and_log_baselines(X_iris, y_iris, dataset_name='iris', seed=seed)\n",
    "    train_and_log_baselines(X_titanic, y_titanic, dataset_name='titanic', seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691e769",
   "metadata": {},
   "source": [
    "#### **Phase 2: Performance Benchmarking**\n",
    "\n",
    "1. **Scalability Testing**\n",
    "\n",
    "- Test with different dataset sizes\n",
    "- Measure training time vs. data volume\n",
    "- Log resource usage (CPU, memory)\n",
    "\n",
    "2. **Hyperparameter Optimization Tracking**\n",
    "\n",
    "- Implement automated hyperparameter sweeps\n",
    "- Compare multiple algorithm performances\n",
    "- Generate performance comparison charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e98d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:14 INFO mlflow.tracking.fluent: Experiment with name 'Scalability Benchmarking Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run wistful-fowl-877 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/d2c59a67b22542e48e4b555204bc8b26\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run sneaky-bear-87 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/4af25ad92b6f48c6b84dba4171dc3331\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run sincere-carp-197 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/05bee106c4394992ba851b71b3db543b\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run charming-panda-577 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/50375f6c88d8412694f01caa24949811\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run illustrious-hen-757 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/09f92374511f4e119ce22adfa3a3d2c1\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run unruly-bat-119 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/8629bb730986479abdc26871bfa518fb\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run hilarious-ape-986 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/556f77d1718849bc91a11dd29971ec1a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run victorious-gull-317 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/9723e4ded94b4aa0af273198b8cb0b46\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run stately-vole-681 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/81cc5c708c4e4453b13ac1d082ce0abe\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run bold-croc-732 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/3a5bea91bcc944dfafe6d1fe90578e02\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run angry-crane-757 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/1072495fd6574a718714576b64bf4d84\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run sneaky-frog-741 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/25fd7129b2914d96b7051d19aa602cda\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run nebulous-ox-405 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/6d769dec9c574605adfbfd7220b8ff63\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run victorious-mole-184 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/6499dbf0697d457cac23fea9c632ef04\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n",
      "ğŸƒ View run magnificent-hog-585 at: http://127.0.0.1:5000/#/experiments/169203641111139527/runs/a7e71ad802954b35a9fe099e633d83f2\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/169203641111139527\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Performance Benchmarking (scalability using synthetic data)\n",
    "from sklearn.datasets import make_classification\n",
    "import time\n",
    "sizes = [1000, 10000, 100000]\n",
    "results = []\n",
    "\n",
    "experiment_name = 'Scalability Benchmarking Experiment'\n",
    "try:\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(f'Warning: could not set experiment \"{experiment_name}\": {e}')\n",
    "\n",
    "for seed in seeds:\n",
    "    for n in sizes:\n",
    "        X_s, y_s = make_classification(n_samples=n, n_features=20, random_state=seed)\n",
    "        Xtr, Xte, ytr, yte = train_test_split(X_s, y_s, test_size=0.2, random_state=seed)\n",
    "        clf = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "        start = time.time()\n",
    "        clf.fit(Xtr, ytr)\n",
    "        elapsed = time.time() - start\n",
    "        ypred = clf.predict(Xte)\n",
    "        acc = accuracy_score(yte, ypred)\n",
    "        results.append({'seed': seed, 'n_samples': n, 'train_time_s': elapsed, 'accuracy': acc})\n",
    "        try:\n",
    "            with mlflow.start_run(nested=True):\n",
    "                mlflow.log_param('seed', seed)\n",
    "                mlflow.log_param('n_samples', n)\n",
    "                mlflow.log_metric('train_time_s', elapsed)\n",
    "                mlflow.log_metric('accuracy', acc)\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b472a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:53:47 INFO mlflow.tracking.fluent: Experiment with name 'Grid Search Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run grid_search_s1000_f10_cv3_seed5162 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/5bb8bfdbb69041c7ba176b33d4389b38\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f10_cv5_seed5162 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/f9aa6d51470b4dac9ac3757776511dde\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv3_seed5162 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/722b5c7cc638441d87a0e533d14b0542\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv5_seed5162 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/39dbcd4e34334ad2bec86ddaab504f2e\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv3_seed5162 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/19b6112e5e7c40b4ada44e09613a479b\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv5_seed5162 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/7dd9079974a94f37bc2c6fce345fc417\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv3_seed5162 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/8fdc9fb840534102896fb172048543f0\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv5_seed5162 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/cb39c5e941454befaf24bc37d194405b\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f10_cv3_seed4445 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/cb0d40f740ef4b6baccd9181cd57a695\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f10_cv5_seed4445 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/87c241a478d04da1adbeda3453234b13\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv3_seed4445 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/83e12c218bcd46f3b637aee42943a0f4\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv5_seed4445 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/d4593c4d5a7046e6a7b54abf3882e9cd\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv3_seed4445 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/af8974c426d5447ca199d2680ad48184\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv5_seed4445 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/32437679b57e479c961fcae057bb944b\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv3_seed4445 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/fe860e3c5d9644278402e03b51f581de\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv5_seed4445 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/b1162c3b5453468bbd90d48db8d5281f\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f10_cv3_seed9689 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/2d443c1d09fc4dfd88c3396a8331935a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f10_cv5_seed9689 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/3ac7f174308d4f03b91eb9766971b49f\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv3_seed9689 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/2d0dae5dd788418493a7bf466f7b307f\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv5_seed9689 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/635c6fb4261b4f2ea99f0a9270b2c8f0\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv3_seed9689 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/b5ebb57822524c52ad8a0f8657e3cee1\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv5_seed9689 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/0fce1be492bc442aaa46ff2025b9c37d\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv3_seed9689 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/8206474681ab4a41b036302d0086d203\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv5_seed9689 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/70beb2698fdc4305b55ca0883b8a3de2\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f10_cv3_seed2628 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/712e6577361c40949d29075f581b7576\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f10_cv5_seed2628 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/46a795e8145c48088c14aaeea4164424\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv3_seed2628 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/57da8d099d32455296f20e7db780af80\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv5_seed2628 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/669c6130b64f40428a97b4fcefc53aea\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv3_seed2628 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/f11b982ff9654771a5c4adbfa3923293\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv5_seed2628 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/3849c3e020854b55878a4d3a0f217a4f\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv3_seed2628 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/3a1ad6924ceb421fb445b3d03168794a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv5_seed2628 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/6c0765fb6dec4534b714add8229a38e0\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f10_cv3_seed4610 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/af27c41eb30842bb8862326cc719fc2c\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f10_cv5_seed4610 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/cc0e997a77ad4926893273e2376745d6\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv3_seed4610 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/55bf9592be2c4512ae674ae2f13fffe5\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s1000_f20_cv5_seed4610 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/ed0dee73550c47aeb8e38bc4dd9563ea\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv3_seed4610 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/92e74d7483d441eab94705704cfa6ade\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f10_cv5_seed4610 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/f92153065bfe46d688f36b3d85777563\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv3_seed4610 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/ef3f510c72c549c5a4833074330c1bad\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "ğŸƒ View run grid_search_s10000_f20_cv5_seed4610 at: http://127.0.0.1:5000/#/experiments/230278427498818056/runs/2d56918e7d5a4fc3ab5b5fbc7efea229\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/230278427498818056\n",
      "Scalability results (first 3): [{'seed': 5162, 'n_samples': 1000, 'train_time_s': 0.026511430740356445, 'accuracy': 0.93}, {'seed': 5162, 'n_samples': 10000, 'train_time_s': 0.2997403144836426, 'accuracy': 0.9495}, {'seed': 5162, 'n_samples': 100000, 'train_time_s': 6.742836952209473, 'accuracy': 0.91735}]\n",
      "Grid search completed for all configurations.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimization tracking: simple GridSearchCV example logged to MLflow\n",
    "param_grid = {'n_estimators': [10, 50], 'max_depth': [None, 10]}\n",
    "\n",
    "# Define lists for looping over different configurations\n",
    "sample_sizes = [1000, 10000]\n",
    "n_features_list = [10, 20]\n",
    "cv_folds = [3, 5]\n",
    "\n",
    "experiment_name = 'Grid Search Experiment'\n",
    "try:\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "except Exception as e:\n",
    "    print(f'Warning: could not set experiment \"{experiment_name}\": {e}')\n",
    "\n",
    "for seed in seeds:\n",
    "    for sample_size in sample_sizes:\n",
    "        for n_features in n_features_list:\n",
    "            for cv_fold in cv_folds:\n",
    "                grid = GridSearchCV(RandomForestClassifier(random_state=seed), param_grid, cv=cv_fold, n_jobs=-1)\n",
    "                X_small, y_small = make_classification(n_samples=sample_size, n_features=n_features, random_state=seed)\n",
    "                grid.fit(X_small, y_small)\n",
    "                try:\n",
    "                    with mlflow.start_run(run_name=f'grid_search_s{sample_size}_f{n_features}_cv{cv_fold}_seed{seed}'):\n",
    "                        mlflow.log_param('seed', seed)\n",
    "                        mlflow.log_param('sample_size', sample_size)\n",
    "                        mlflow.log_param('n_features', n_features)\n",
    "                        mlflow.log_param('cv_folds', cv_fold)\n",
    "                        mlflow.log_params(grid.best_params_)\n",
    "                        mlflow.log_metric('best_score', grid.best_score_)\n",
    "                        mlflow.log_metric('mean_cv_score', grid.cv_results_['mean_test_score'].mean())\n",
    "                        mlflow.log_metric('std_cv_score', grid.cv_results_['std_test_score'].mean())\n",
    "                        mlflow.log_metric('best_index', grid.best_index_)\n",
    "                        cv_results = pd.DataFrame(grid.cv_results_)\n",
    "                        csv_filename = f'temp/grid_search_s{sample_size}_f{n_features}_cv{cv_fold}_seed{seed}.csv'\n",
    "                        cv_results.to_csv(csv_filename,index=False)\n",
    "                        try:\n",
    "                            mlflow.log_artifact(csv_filename)\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "print('Scalability results (first 3):', results[:3])\n",
    "print('Grid search completed for all configurations.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c53d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp folder does not exist\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Remove all files and subdirectories inside the 'temp' folder\n",
    "if os.path.exists('temp'):\n",
    "    for filename in os.listdir('temp'):\n",
    "        file_path = os.path.join('temp', filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "                print(f'Deleted file: {file_path}')\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "                print(f'Deleted directory: {file_path}')\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "else:\n",
    "    print('temp folder does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28fb58e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI -> http://127.0.0.1:5000\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run popular-gnu-304 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/0e86d2f0991f48d7971d5239a5827940\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run persistent-goose-186 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/d0754479222040c188f52987df7aed57\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run spiffy-shrike-637 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/c24b316abaa345339cbe9f0f6b2cb986\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:24 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run abrasive-fly-211 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/d11f290111df4660bfd1c8faaa49c204\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run carefree-pug-674 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/36381a3757fc47bbb9e51183bbda27c8\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run funny-duck-940 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/3b1e1bb93f974b2a83e720755a2674c1\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run crawling-crow-738 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/88cb2999b93f4b2abd444d2b3d1ce380\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run chill-finch-549 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/be91b78c8d084b089e804ca65197876c\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run unequaled-snail-852 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/6c8360207a9241f29d413897025124d0\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run colorful-conch-866 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/aa8551dfbdc54117bf31083e99be1e90\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run brawny-goat-799 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/d5c0e39e7f5c4604bbd7d9595fd9d7b5\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run sincere-colt-453 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/51f800cf251046f69db29fbdc36d1a8a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run kindly-crab-127 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/3793197b69e44bc881066821bbfd8f00\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run abundant-rook-595 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/9e290bc0928d44b7b605ba2bb6422404\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run luxuriant-kit-728 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/bfbf1369b9814306b2b0e21dca67780b\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run illustrious-stag-295 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/482b64a01bc246e0b29a7c9551de0013\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run rebellious-ape-638 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/b30952d8b3bb48d390c7a2963dcdac90\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run capricious-shark-657 at: http://127.0.0.1:5000/#/experiments/850610778473313578/runs/38ff0af9535844debec16983396d38de\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/850610778473313578\n",
      "MLflow tracking URI -> http://127.0.0.1:5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run thundering-pig-505 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/78a4beb62c4240da92ff1f229f58d128\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:55:30 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run unique-kite-331 at: http://127.0.0.1:5000/#/experiments/522953733460524095/runs/e5c04bf172ad4deebda7d69da07262c9\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/522953733460524095\n",
      "Baseline runs logged to remote MLflow server.\n"
     ]
    }
   ],
   "source": [
    "# MLflow client: point to the MLflow server and run the baseline logging remotely\n",
    "import mlflow\n",
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "MLFLOW_SERVER = 'http://127.0.0.1:5000'  \n",
    "mlflow.set_tracking_uri(MLFLOW_SERVER)\n",
    "print('MLflow tracking URI ->', mlflow.get_tracking_uri())\n",
    "try:\n",
    "    for seed in seeds:\n",
    "        train_and_log_baselines(X_iris, y_iris, dataset_name='iris', seed=seed)\n",
    "        train_and_log_baselines(X_titanic, y_titanic, dataset_name='titanic', seed=seed)\n",
    "    print('Baseline runs logged to remote MLflow server.')\n",
    "except NameError as e:\n",
    "    print('Required data or helper function not found in scope:', e)\n",
    "except Exception as e:\n",
    "    print('Error while running remote logging:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab15a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Hasan Al Hasan - Advanced Features & Model Management**\n",
    "\n",
    "#### **Phase 1: Research & Advanced Setup**\n",
    "\n",
    "1. **MLflow Components Deep Dive**\n",
    "\n",
    "- Study Model Registry, Projects, and Models components\n",
    "- Research MLflow's deployment capabilities\n",
    "- Compare tracking UI alternatives\n",
    "\n",
    "2. **Advanced Environment Setup**\n",
    "\n",
    "- Set up MLflow Model Registry\n",
    "- Configure artifact storage (local + cloud options)\n",
    "- Prepare Docker environment for model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70279140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 - Research & Advanced Setup (Hasan)\n",
    "# - Read MLflow Model Registry and Projects documentation\n",
    "# - Design artifact storage strategy (local vs cloud)\n",
    "# - Draft Dockerfile and serving container notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02c5c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHASE 1: RESEARCH & ADVANCED SETUP\n",
      "============================================================\n",
      "\n",
      "### 1. MLflow Components Deep Dive ###\n",
      "\n",
      "\n",
      "ğŸ“¦ MLflow Tracking\n",
      "   Purpose: Log and query experiments: parameters, metrics, artifacts\n",
      "   Key Features:\n",
      "      - Experiment organization\n",
      "      - Run management\n",
      "      - Metric logging\n",
      "      - Artifact storage\n",
      "   Status: âœ“ Already implemented by Jabir\n",
      "\n",
      "ğŸ“¦ MLflow Projects\n",
      "   Purpose: Package ML code in reusable, reproducible format\n",
      "   Key Features:\n",
      "      - Conda/Docker environment specification\n",
      "      - Entry points definition\n",
      "      - Parameter configuration\n",
      "      - Git integration\n",
      "   Use Case: Share ML code across team, reproduce experiments\n",
      "   Example: MLproject file with conda.yaml dependencies\n",
      "\n",
      "ğŸ“¦ MLflow Models\n",
      "   Purpose: Deploy models in diverse serving environments\n",
      "   Key Features:\n",
      "      - Standard model packaging format\n",
      "      - Multiple 'flavors' (sklearn, tensorflow, pytorch, etc.)\n",
      "      - Model signature (input/output schema)\n",
      "      - Model versioning\n",
      "   Deployment Options:\n",
      "      - REST API (mlflow models serve)\n",
      "      - Docker containers\n",
      "      - Cloud platforms (AWS SageMaker, Azure ML)\n",
      "      - Batch inference\n",
      "\n",
      "ğŸ“¦ MLflow Model Registry\n",
      "   Purpose: Centralized model store with versioning and stage transitions\n",
      "   Key Features:\n",
      "      - Model versioning (v1, v2, v3...)\n",
      "      - Stage management (None â†’ Staging â†’ Production â†’ Archived)\n",
      "      - Model lineage tracking\n",
      "      - Annotations and descriptions\n",
      "   Workflow: Register â†’ Stage (Staging) â†’ Validate â†’ Promote (Production)\n",
      "   Status: ğŸ¯ To be implemented in Phase 2\n",
      "\n",
      "\n",
      "### 2. MLflow Deployment Capabilities ###\n",
      "\n",
      "\n",
      "ğŸš€ Local REST API\n",
      "   Command: mlflow models serve -m models:/model_name/Production -p 5001\n",
      "   Pros:\n",
      "      - Quick testing\n",
      "      - No infrastructure needed\n",
      "   Cons:\n",
      "      - Not production-ready\n",
      "      - No scaling\n",
      "   Use Case: Development and testing\n",
      "\n",
      "ğŸš€ Docker Container\n",
      "   Command: mlflow models build-docker -m models:/model_name/Production -n my-model\n",
      "   Pros:\n",
      "      - Portable\n",
      "      - Reproducible\n",
      "      - Can deploy anywhere\n",
      "   Cons:\n",
      "      - Requires Docker knowledge\n",
      "      - Image size can be large\n",
      "   Use Case: Cloud deployment, Kubernetes\n",
      "\n",
      "ğŸš€ Cloud Platforms\n",
      "   AWS SageMaker: mlflow sagemaker deploy -m models:/model_name/Production\n",
      "   Azure ML: mlflow azureml deploy -m models:/model_name/Production\n",
      "   Pros:\n",
      "      - Managed service\n",
      "      - Auto-scaling\n",
      "      - Production-grade\n",
      "   Cons:\n",
      "      - Cost\n",
      "      - Cloud vendor lock-in\n",
      "   Use Case: Production deployment at scale\n",
      "\n",
      "ğŸš€ Batch Inference\n",
      "   Method: Load model and run predictions on large datasets\n",
      "   Code: model = mlflow.pyfunc.load_model('models:/model/Production')\n",
      "   Use Case: Scheduled predictions, data pipelines\n",
      "\n",
      "\n",
      "### 3. MLflow Tracking UI Alternatives ###\n",
      "\n",
      "Tool                      Pros                                     Best For                      \n",
      "-----------------------------------------------------------------------------------------------\n",
      "MLflow UI (Built-in)      Free                                     Individual researchers, small projects\n",
      "Weights & Biases (W&B)    Rich visualizations                      Teams needing advanced visualization\n",
      "Neptune.ai                Metadata organization                    Enterprise ML teams           \n",
      "TensorBoard               Great for deep learning                  Deep learning experiments     \n",
      "\n",
      "âœ“ Recommendation for this project: MLflow UI (built-in) - sufficient for demo purposes\n",
      "\n",
      "============================================================\n",
      "Phase 1.1 Complete: MLflow Components Research Done\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Phase 1.1 - MLflow Components Deep Dive (Hasan)\n",
    "# Research and document MLflow's advanced components\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PHASE 1: RESEARCH & ADVANCED SETUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# 1. MLflow Components Overview\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n### 1. MLflow Components Deep Dive ###\\n\")\n",
    "\n",
    "components_overview = {\n",
    "    \"MLflow Tracking\": {\n",
    "        \"Purpose\": \"Log and query experiments: parameters, metrics, artifacts\",\n",
    "        \"Key Features\": [\n",
    "            \"- Experiment organization\",\n",
    "            \"- Run management\",\n",
    "            \"- Metric logging\",\n",
    "            \"- Artifact storage\"\n",
    "        ],\n",
    "        \"Status\": \"âœ“ Already implemented by Jabir\"\n",
    "    },\n",
    "    \n",
    "    \"MLflow Projects\": {\n",
    "        \"Purpose\": \"Package ML code in reusable, reproducible format\",\n",
    "        \"Key Features\": [\n",
    "            \"- Conda/Docker environment specification\",\n",
    "            \"- Entry points definition\",\n",
    "            \"- Parameter configuration\",\n",
    "            \"- Git integration\"\n",
    "        ],\n",
    "        \"Use Case\": \"Share ML code across team, reproduce experiments\",\n",
    "        \"Example\": \"MLproject file with conda.yaml dependencies\"\n",
    "    },\n",
    "    \n",
    "    \"MLflow Models\": {\n",
    "        \"Purpose\": \"Deploy models in diverse serving environments\",\n",
    "        \"Key Features\": [\n",
    "            \"- Standard model packaging format\",\n",
    "            \"- Multiple 'flavors' (sklearn, tensorflow, pytorch, etc.)\",\n",
    "            \"- Model signature (input/output schema)\",\n",
    "            \"- Model versioning\"\n",
    "        ],\n",
    "        \"Deployment Options\": [\n",
    "            \"- REST API (mlflow models serve)\",\n",
    "            \"- Docker containers\",\n",
    "            \"- Cloud platforms (AWS SageMaker, Azure ML)\",\n",
    "            \"- Batch inference\"\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    \"MLflow Model Registry\": {\n",
    "        \"Purpose\": \"Centralized model store with versioning and stage transitions\",\n",
    "        \"Key Features\": [\n",
    "            \"- Model versioning (v1, v2, v3...)\",\n",
    "            \"- Stage management (None â†’ Staging â†’ Production â†’ Archived)\",\n",
    "            \"- Model lineage tracking\",\n",
    "            \"- Annotations and descriptions\"\n",
    "        ],\n",
    "        \"Workflow\": \"Register â†’ Stage (Staging) â†’ Validate â†’ Promote (Production)\",\n",
    "        \"Status\": \"ğŸ¯ To be implemented in Phase 2\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Print all components with full details\n",
    "for component, details in components_overview.items():\n",
    "    print(f\"\\nğŸ“¦ {component}\")\n",
    "    print(f\"   Purpose: {details['Purpose']}\")\n",
    "    \n",
    "    if 'Key Features' in details:\n",
    "        print(\"   Key Features:\")\n",
    "        for feature in details['Key Features']:\n",
    "            print(f\"      {feature}\")\n",
    "    \n",
    "    if 'Deployment Options' in details:\n",
    "        print(\"   Deployment Options:\")\n",
    "        for option in details['Deployment Options']:\n",
    "            print(f\"      {option}\")\n",
    "    \n",
    "    if 'Use Case' in details:\n",
    "        print(f\"   Use Case: {details['Use Case']}\")\n",
    "    \n",
    "    if 'Example' in details:\n",
    "        print(f\"   Example: {details['Example']}\")\n",
    "    \n",
    "    if 'Workflow' in details:\n",
    "        print(f\"   Workflow: {details['Workflow']}\")\n",
    "    \n",
    "    if 'Status' in details:\n",
    "        print(f\"   Status: {details['Status']}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. MLflow Deployment Capabilities Research\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\n### 2. MLflow Deployment Capabilities ###\\n\")\n",
    "\n",
    "deployment_methods = {\n",
    "    \"Local REST API\": {\n",
    "        \"Command\": \"mlflow models serve -m models:/model_name/Production -p 5001\",\n",
    "        \"Pros\": [\"Quick testing\", \"No infrastructure needed\"],\n",
    "        \"Cons\": [\"Not production-ready\", \"No scaling\"],\n",
    "        \"Use Case\": \"Development and testing\"\n",
    "    },\n",
    "    \n",
    "    \"Docker Container\": {\n",
    "        \"Command\": \"mlflow models build-docker -m models:/model_name/Production -n my-model\",\n",
    "        \"Pros\": [\"Portable\", \"Reproducible\", \"Can deploy anywhere\"],\n",
    "        \"Cons\": [\"Requires Docker knowledge\", \"Image size can be large\"],\n",
    "        \"Use Case\": \"Cloud deployment, Kubernetes\"\n",
    "    },\n",
    "    \n",
    "    \"Cloud Platforms\": {\n",
    "        \"AWS SageMaker\": \"mlflow sagemaker deploy -m models:/model_name/Production\",\n",
    "        \"Azure ML\": \"mlflow azureml deploy -m models:/model_name/Production\",\n",
    "        \"Pros\": [\"Managed service\", \"Auto-scaling\", \"Production-grade\"],\n",
    "        \"Cons\": [\"Cost\", \"Cloud vendor lock-in\"],\n",
    "        \"Use Case\": \"Production deployment at scale\"\n",
    "    },\n",
    "    \n",
    "    \"Batch Inference\": {\n",
    "        \"Method\": \"Load model and run predictions on large datasets\",\n",
    "        \"Code\": \"model = mlflow.pyfunc.load_model('models:/model/Production')\",\n",
    "        \"Use Case\": \"Scheduled predictions, data pipelines\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for method, details in deployment_methods.items():\n",
    "    print(f\"\\nğŸš€ {method}\")\n",
    "    for key, value in details.items():\n",
    "        if isinstance(value, list):\n",
    "            print(f\"   {key}:\")\n",
    "            for item in value:\n",
    "                print(f\"      - {item}\")\n",
    "        else:\n",
    "            print(f\"   {key}: {value}\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. Tracking UI Alternatives Comparison\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\\n### 3. MLflow Tracking UI Alternatives ###\\n\")\n",
    "\n",
    "ui_alternatives = {\n",
    "    \"MLflow UI (Built-in)\": {\n",
    "        \"Pros\": [\"Free\", \"Built-in\", \"Simple\", \"Good for small teams\"],\n",
    "        \"Cons\": [\"Basic features\", \"Limited collaboration tools\"],\n",
    "        \"Best For\": \"Individual researchers, small projects\"\n",
    "    },\n",
    "    \n",
    "    \"Weights & Biases (W&B)\": {\n",
    "        \"Pros\": [\"Rich visualizations\", \"Team collaboration\", \"Model comparison\"],\n",
    "        \"Cons\": [\"Paid (free tier limited)\", \"Cloud-dependent\"],\n",
    "        \"Best For\": \"Teams needing advanced visualization\"\n",
    "    },\n",
    "    \n",
    "    \"Neptune.ai\": {\n",
    "        \"Pros\": [\"Metadata organization\", \"Long-term experiment storage\"],\n",
    "        \"Cons\": [\"Paid service\", \"Learning curve\"],\n",
    "        \"Best For\": \"Enterprise ML teams\"\n",
    "    },\n",
    "    \n",
    "    \"TensorBoard\": {\n",
    "        \"Pros\": [\"Great for deep learning\", \"Real-time training monitoring\"],\n",
    "        \"Cons\": [\"Limited to TensorFlow/PyTorch\", \"Not for general ML\"],\n",
    "        \"Best For\": \"Deep learning experiments\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"{'Tool':<25} {'Pros':<40} {'Best For':<30}\")\n",
    "print(\"-\" * 95)\n",
    "for tool, details in ui_alternatives.items():\n",
    "    pros_summary = details['Pros'][0] if details['Pros'] else \"N/A\"\n",
    "    print(f\"{tool:<25} {pros_summary:<40} {details['Best For']:<30}\")\n",
    "\n",
    "print(\"\\nâœ“ Recommendation for this project: MLflow UI (built-in) - sufficient for demo purposes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Phase 1.1 Complete: MLflow Components Research Done\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98772712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PHASE 1.2: ENVIRONMENT SETUP & CONFIGURATION\n",
      "============================================================\n",
      "\n",
      "### 1. Artifact Storage Strategy ###\n",
      "\n",
      "ğŸ“‚ Artifact Storage Options:\n",
      "\n",
      "Option: Local File System\n",
      "  Path: ./mlruns\n",
      "  Pros: Simple, No setup needed, Fast for development\n",
      "  Cons: Not scalable, No backup, Single machine only\n",
      "  Best For: Development, single user, small datasets\n",
      "\n",
      "Option: Amazon S3\n",
      "  Path: s3://my-mlflow-bucket/artifacts\n",
      "  Pros: Scalable, Durable, Team accessible, Automatic backup\n",
      "  Cons: Requires AWS setup, Cost, Network dependency\n",
      "  Best For: Production, team collaboration, large artifacts\n",
      "\n",
      "Option: Azure Blob Storage\n",
      "  Path: wasbs://container@account.blob.core.windows.net/path\n",
      "  Pros: Azure integration, Scalable, Team accessible\n",
      "  Cons: Requires Azure setup, Cost\n",
      "  Best For: Organizations using Azure cloud\n",
      "\n",
      "Option: Network File System (NFS)\n",
      "  Path: /mnt/shared/mlruns\n",
      "  Pros: Shared across machines, No cloud needed\n",
      "  Cons: Requires network setup, Performance issues\n",
      "  Best For: On-premise team environments\n",
      "\n",
      "### 2. Selected Strategy for This Project ###\n",
      "\n",
      "âœ“ Strategy: Local File System (for simplicity)\n",
      "  Reason: Sufficient for academic demo, no cloud setup required\n",
      "  Path: ./mlruns\n",
      "  Backup Plan: Can migrate to S3/Azure if needed for production\n",
      "\n",
      "âœ“ Created directory: mlruns/\n",
      "âœ“ Created directory: deployment/\n",
      "âœ“ Created directory: temp/\n",
      "âœ“ Created directory: model_artifacts/\n",
      "\n",
      "### 3. MLflow Model Registry Configuration ###\n",
      "\n",
      "ğŸ—„ï¸ Model Registry Configuration:\n",
      "\n",
      "Backend Store:\n",
      "  Type: File-based (SQLite)\n",
      "  Path: ./mlruns/mlflow.db\n",
      "  Command: mlflow server --backend-store-uri sqlite:///mlruns/mlflow.db --default-artifact-root ./mlruns\n",
      "  Note: For production, use PostgreSQL or MySQL\n",
      "\n",
      "Artifact Store:\n",
      "  Type: Local filesystem\n",
      "  Path: ./mlruns\n",
      "  Note: For production, use S3 or Azure Blob\n",
      "\n",
      "Server Mode:\n",
      "  Host: 127.0.0.1\n",
      "  Port: 5000\n",
      "  Command: mlflow server --host 127.0.0.1 --port 5000\n",
      "\n",
      "Current Tracking URI: http://127.0.0.1:5000\n",
      "\n",
      "### 4. Docker Environment Preparation ###\n",
      "\n",
      "ğŸ“‹ Docker Setup Checklist:\n",
      "  âœ“ Install Docker Desktop (https://www.docker.com/products/docker-desktop)\n",
      "  âœ“ Verify installation: docker --version\n",
      "  âœ“ Test Docker: docker run hello-world\n",
      "  â–¡ Create Dockerfile for MLflow model serving (Phase 2)\n",
      "  â–¡ Create docker-compose.yml for multi-container setup (Phase 2)\n",
      "  â–¡ Build Docker image (Phase 2)\n",
      "  â–¡ Test container locally (Phase 2)\n",
      "\n",
      "ğŸ“ Dockerfile Template (to be created in Phase 2):\n",
      "\n",
      "FROM python:3.9-slim\n",
      "\n",
      "# Install MLflow and dependencies\n",
      "RUN pip install mlflow scikit-learn pandas numpy\n",
      "\n",
      "# Set working directory\n",
      "WORKDIR /app\n",
      "\n",
      "# Expose serving port\n",
      "EXPOSE 5001\n",
      "\n",
      "# Serve model (command to be specified in Phase 2)\n",
      "CMD [\"mlflow\", \"models\", \"serve\", \"-m\", \"models:/model_name/Production\", \"-p\", \"5001\", \"--host\", \"0.0.0.0\"]\n",
      "\n",
      "\n",
      "### 5. MLproject File Configuration ###\n",
      "\n",
      "ğŸ“„ MLproject Template:\n",
      "name: mlflow-evaluation-project\n",
      "\n",
      "conda_env: conda.yaml\n",
      "\n",
      "entry_points:\n",
      "  main:\n",
      "    parameters:\n",
      "      dataset: {type: string, default: \"iris\"}\n",
      "      model: {type: string, default: \"random_forest\"}\n",
      "      seed: {type: int, default: 42}\n",
      "    command: \"python train.py --dataset {dataset} --model {model} --seed {seed}\"\n",
      "\n",
      "  serve:\n",
      "    parameters:\n",
      "      model_name: {type: string}\n",
      "      port: {type: int, default: 5001}\n",
      "    command: \"mlflow models serve -m models:/{model_name}/Production -p {port}\"\n",
      "\n",
      "âœ“ MLproject file saved\n",
      "\n",
      "### 6. Conda Environment Configuration ###\n",
      "\n",
      "ğŸ“„ conda.yaml Template:\n",
      "name: mlflow-env\n",
      "channels:\n",
      "  - defaults\n",
      "dependencies:\n",
      "  - python=3.9\n",
      "  - pip\n",
      "  - pip:\n",
      "    - mlflow\n",
      "    - scikit-learn\n",
      "    - pandas\n",
      "    - numpy\n",
      "    - seaborn\n",
      "    - matplotlib\n",
      "\n",
      "âœ“ conda.yaml file saved\n",
      "\n",
      "\n",
      "=== PHASE 1 COMPLETION NOTES ===\n",
      "\n",
      "âœ“ Researched MLflow components: Tracking, Projects, Models, Model Registry\n",
      "âœ“ Evaluated deployment options: REST API, Docker, Cloud, Batch\n",
      "âœ“ Compared tracking UI alternatives: MLflow UI vs W&B vs Neptune\n",
      "âœ“ Designed artifact storage strategy: Local filesystem (with S3 migration path)\n",
      "âœ“ Configured Model Registry: SQLite backend, local artifacts\n",
      "âœ“ Prepared Docker environment checklist\n",
      "âœ“ Created MLproject file for reproducibility\n",
      "âœ“ Created conda.yaml for environment management\n",
      "\n",
      "NEXT STEPS (Phase 2):\n",
      "1. Implement Model Registry with actual model registration\n",
      "2. Create stage transition workflows (Staging â†’ Production)\n",
      "3. Build Docker container for model serving\n",
      "4. Log artifacts (confusion matrix, ROC curves, feature importance)\n",
      "5. Test REST API endpoints for model inference\n",
      "6. Demonstrate A/B testing capabilities\n",
      "\n",
      "DELIVERABLES FROM PHASE 1:\n",
      "- Research documentation\n",
      "- Configuration strategy\n",
      "- Directory structure created: mlruns/, deployment/, temp/, model_artifacts/\n",
      "- Docker preparation checklist\n",
      "- MLproject file\n",
      "- conda.yaml file\n",
      "- phase1_completion_notes.txt\n",
      "\n",
      "\n",
      "============================================================\n",
      "âœ“ PHASE 1 COMPLETE: Ready for Phase 2 Implementation\n",
      "============================================================\n",
      "\n",
      "### Files Created in Phase 1 ###\n",
      "  âœ“ MLproject\n",
      "  âœ“ conda.yaml\n",
      "  âœ“ phase1_completion_notes.txt\n",
      "\n",
      "### Directories Created ###\n",
      "  âœ“ mlruns/\n",
      "  âœ“ deployment/\n",
      "  âœ“ temp/\n",
      "  âœ“ model_artifacts/\n"
     ]
    }
   ],
   "source": [
    "# Phase 1.2 - Advanced Environment Setup Planning (Hasan)\n",
    "# Design artifact storage strategy and prepare infrastructure\n",
    "\n",
    "import os\n",
    "import mlflow\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PHASE 1.2: ENVIRONMENT SETUP & CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# 1. Artifact Storage Strategy Design\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n### 1. Artifact Storage Strategy ###\\n\")\n",
    "\n",
    "storage_strategies = {\n",
    "    \"Local File System\": {\n",
    "        \"Path\": \"./mlruns\",\n",
    "        \"Pros\": [\"Simple\", \"No setup needed\", \"Fast for development\"],\n",
    "        \"Cons\": [\"Not scalable\", \"No backup\", \"Single machine only\"],\n",
    "        \"Configuration\": \"mlflow.set_tracking_uri('./mlruns')\",\n",
    "        \"Best For\": \"Development, single user, small datasets\",\n",
    "        \"Artifacts Stored\": [\"Models\", \"Plots\", \"Metrics\", \"Parameters\"]\n",
    "    },\n",
    "    \n",
    "    \"Amazon S3\": {\n",
    "        \"Path\": \"s3://my-mlflow-bucket/artifacts\",\n",
    "        \"Pros\": [\"Scalable\", \"Durable\", \"Team accessible\", \"Automatic backup\"],\n",
    "        \"Cons\": [\"Requires AWS setup\", \"Cost\", \"Network dependency\"],\n",
    "        \"Configuration\": \"\"\"\n",
    "            export MLFLOW_S3_ENDPOINT_URL=https://s3.amazonaws.com\n",
    "            mlflow.set_tracking_uri('mysql://user:pass@host/db')\n",
    "            export MLFLOW_ARTIFACT_ROOT=s3://bucket/path\n",
    "        \"\"\",\n",
    "        \"Best For\": \"Production, team collaboration, large artifacts\",\n",
    "        \"Prerequisites\": [\"AWS account\", \"S3 bucket\", \"IAM credentials\"]\n",
    "    },\n",
    "    \n",
    "    \"Azure Blob Storage\": {\n",
    "        \"Path\": \"wasbs://container@account.blob.core.windows.net/path\",\n",
    "        \"Pros\": [\"Azure integration\", \"Scalable\", \"Team accessible\"],\n",
    "        \"Cons\": [\"Requires Azure setup\", \"Cost\"],\n",
    "        \"Configuration\": \"\"\"\n",
    "            export AZURE_STORAGE_CONNECTION_STRING=\"...\"\n",
    "            export MLFLOW_ARTIFACT_ROOT=wasbs://container@account/path\n",
    "        \"\"\",\n",
    "        \"Best For\": \"Organizations using Azure cloud\"\n",
    "    },\n",
    "    \n",
    "    \"Network File System (NFS)\": {\n",
    "        \"Path\": \"/mnt/shared/mlruns\",\n",
    "        \"Pros\": [\"Shared across machines\", \"No cloud needed\"],\n",
    "        \"Cons\": [\"Requires network setup\", \"Performance issues\"],\n",
    "        \"Best For\": \"On-premise team environments\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‚ Artifact Storage Options:\\n\")\n",
    "for storage, details in storage_strategies.items():\n",
    "    print(f\"Option: {storage}\")\n",
    "    print(f\"  Path: {details['Path']}\")\n",
    "    print(f\"  Pros: {', '.join(details['Pros'])}\")\n",
    "    print(f\"  Cons: {', '.join(details['Cons'])}\")\n",
    "    print(f\"  Best For: {details['Best For']}\")\n",
    "    print()\n",
    "\n",
    "# ============================================================\n",
    "# 2. Chosen Strategy for This Project\n",
    "# ============================================================\n",
    "\n",
    "print(\"### 2. Selected Strategy for This Project ###\\n\")\n",
    "print(\"âœ“ Strategy: Local File System (for simplicity)\")\n",
    "print(\"  Reason: Sufficient for academic demo, no cloud setup required\")\n",
    "print(\"  Path: ./mlruns\")\n",
    "print(\"  Backup Plan: Can migrate to S3/Azure if needed for production\\n\")\n",
    "\n",
    "# Create artifact directories\n",
    "artifact_dirs = ['mlruns', 'deployment', 'temp', 'model_artifacts']\n",
    "for dir_name in artifact_dirs:\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "    print(f\"âœ“ Created directory: {dir_name}/\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. MLflow Model Registry Setup (Local)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n### 3. MLflow Model Registry Configuration ###\\n\")\n",
    "\n",
    "registry_config = {\n",
    "    \"Backend Store\": {\n",
    "        \"Type\": \"File-based (SQLite)\",\n",
    "        \"Path\": \"./mlruns/mlflow.db\",\n",
    "        \"Command\": \"mlflow server --backend-store-uri sqlite:///mlruns/mlflow.db --default-artifact-root ./mlruns\",\n",
    "        \"Note\": \"For production, use PostgreSQL or MySQL\"\n",
    "    },\n",
    "    \n",
    "    \"Artifact Store\": {\n",
    "        \"Type\": \"Local filesystem\",\n",
    "        \"Path\": \"./mlruns\",\n",
    "        \"Note\": \"For production, use S3 or Azure Blob\"\n",
    "    },\n",
    "    \n",
    "    \"Server Mode\": {\n",
    "        \"Host\": \"127.0.0.1\",\n",
    "        \"Port\": \"5000\",\n",
    "        \"Command\": \"mlflow server --host 127.0.0.1 --port 5000\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ—„ï¸ Model Registry Configuration:\\n\")\n",
    "for component, details in registry_config.items():\n",
    "    print(f\"{component}:\")\n",
    "    for key, value in details.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print()\n",
    "\n",
    "# Verify current tracking URI\n",
    "current_uri = mlflow.get_tracking_uri()\n",
    "print(f\"Current Tracking URI: {current_uri}\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Docker Environment Preparation (Documentation Only)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n### 4. Docker Environment Preparation ###\\n\")\n",
    "\n",
    "print(\"ğŸ“‹ Docker Setup Checklist:\")\n",
    "docker_checklist = [\n",
    "    \"âœ“ Install Docker Desktop (https://www.docker.com/products/docker-desktop)\",\n",
    "    \"âœ“ Verify installation: docker --version\",\n",
    "    \"âœ“ Test Docker: docker run hello-world\",\n",
    "    \"â–¡ Create Dockerfile for MLflow model serving (Phase 2)\",\n",
    "    \"â–¡ Create docker-compose.yml for multi-container setup (Phase 2)\",\n",
    "    \"â–¡ Build Docker image (Phase 2)\",\n",
    "    \"â–¡ Test container locally (Phase 2)\"\n",
    "]\n",
    "\n",
    "for item in docker_checklist:\n",
    "    print(f\"  {item}\")\n",
    "\n",
    "print(\"\\nğŸ“ Dockerfile Template (to be created in Phase 2):\")\n",
    "dockerfile_template = \"\"\"\n",
    "FROM python:3.9-slim\n",
    "\n",
    "# Install MLflow and dependencies\n",
    "RUN pip install mlflow scikit-learn pandas numpy\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Expose serving port\n",
    "EXPOSE 5001\n",
    "\n",
    "# Serve model (command to be specified in Phase 2)\n",
    "CMD [\"mlflow\", \"models\", \"serve\", \"-m\", \"models:/model_name/Production\", \"-p\", \"5001\", \"--host\", \"0.0.0.0\"]\n",
    "\"\"\"\n",
    "print(dockerfile_template)\n",
    "\n",
    "# ============================================================\n",
    "# 5. MLproject File Creation (Reproducibility)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n### 5. MLproject File Configuration ###\\n\")\n",
    "\n",
    "mlproject_content = \"\"\"name: mlflow-evaluation-project\n",
    "\n",
    "conda_env: conda.yaml\n",
    "\n",
    "entry_points:\n",
    "  main:\n",
    "    parameters:\n",
    "      dataset: {type: string, default: \"iris\"}\n",
    "      model: {type: string, default: \"random_forest\"}\n",
    "      seed: {type: int, default: 42}\n",
    "    command: \"python train.py --dataset {dataset} --model {model} --seed {seed}\"\n",
    "  \n",
    "  serve:\n",
    "    parameters:\n",
    "      model_name: {type: string}\n",
    "      port: {type: int, default: 5001}\n",
    "    command: \"mlflow models serve -m models:/{model_name}/Production -p {port}\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“„ MLproject Template:\")\n",
    "print(mlproject_content)\n",
    "\n",
    "# Save MLproject file\n",
    "with open('MLproject', 'w') as f:\n",
    "    f.write(mlproject_content)\n",
    "print(\"âœ“ MLproject file saved\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. Conda Environment Configuration\n",
    "# ============================================================\n",
    "\n",
    "print(\"### 6. Conda Environment Configuration ###\\n\")\n",
    "\n",
    "conda_yaml = \"\"\"name: mlflow-env\n",
    "channels:\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - python=3.9\n",
    "  - pip\n",
    "  - pip:\n",
    "    - mlflow\n",
    "    - scikit-learn\n",
    "    - pandas\n",
    "    - numpy\n",
    "    - seaborn\n",
    "    - matplotlib\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“„ conda.yaml Template:\")\n",
    "print(conda_yaml)\n",
    "\n",
    "# Save conda.yaml file\n",
    "with open('conda.yaml', 'w') as f:\n",
    "    f.write(conda_yaml)\n",
    "print(\"âœ“ conda.yaml file saved\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. Phase 1 Completion Summary\n",
    "# ============================================================\n",
    "\n",
    "# Save planning notes\n",
    "planning_notes = \"\"\"\n",
    "=== PHASE 1 COMPLETION NOTES ===\n",
    "\n",
    "âœ“ Researched MLflow components: Tracking, Projects, Models, Model Registry\n",
    "âœ“ Evaluated deployment options: REST API, Docker, Cloud, Batch\n",
    "âœ“ Compared tracking UI alternatives: MLflow UI vs W&B vs Neptune\n",
    "âœ“ Designed artifact storage strategy: Local filesystem (with S3 migration path)\n",
    "âœ“ Configured Model Registry: SQLite backend, local artifacts\n",
    "âœ“ Prepared Docker environment checklist\n",
    "âœ“ Created MLproject file for reproducibility\n",
    "âœ“ Created conda.yaml for environment management\n",
    "\n",
    "NEXT STEPS (Phase 2):\n",
    "1. Implement Model Registry with actual model registration\n",
    "2. Create stage transition workflows (Staging â†’ Production)\n",
    "3. Build Docker container for model serving\n",
    "4. Log artifacts (confusion matrix, ROC curves, feature importance)\n",
    "5. Test REST API endpoints for model inference\n",
    "6. Demonstrate A/B testing capabilities\n",
    "\n",
    "DELIVERABLES FROM PHASE 1:\n",
    "- Research documentation\n",
    "- Configuration strategy\n",
    "- Directory structure created: mlruns/, deployment/, temp/, model_artifacts/\n",
    "- Docker preparation checklist\n",
    "- MLproject file\n",
    "- conda.yaml file\n",
    "- phase1_completion_notes.txt\n",
    "\"\"\"\n",
    "\n",
    "# Save planning notes to file (WITH UTF-8 ENCODING)\n",
    "with open('phase1_completion_notes.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(planning_notes)\n",
    "\n",
    "print(planning_notes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ PHASE 1 COMPLETE: Ready for Phase 2 Implementation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# List created files\n",
    "print(\"\\n### Files Created in Phase 1 ###\")\n",
    "phase1_files = ['MLproject', 'conda.yaml', 'phase1_completion_notes.txt']\n",
    "for file in phase1_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"  âœ“ {file}\")\n",
    "    else:\n",
    "        print(f\"  âœ— {file} (not found)\")\n",
    "\n",
    "print(\"\\n### Directories Created ###\")\n",
    "for dir_name in artifact_dirs:\n",
    "    if os.path.exists(dir_name):\n",
    "        print(f\"  âœ“ {dir_name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccba2457",
   "metadata": {},
   "source": [
    "#### **Phase 2: Advanced Feature Implementation**\n",
    "\n",
    "1. **Model Registry & Versioning**\n",
    "\n",
    "- Implement model versioning and staging\n",
    "- Set up transition workflows (Staging â†’ Production)\n",
    "\n",
    "2. **Model Serving & Deployment**\n",
    "\n",
    "- Create REST API endpoints for model serving\n",
    "- Test batch and real-time inference\n",
    "- Demonstrate model A/B testing capabilities\n",
    "\n",
    "3. **Artifact Management**\n",
    "\n",
    "- Log confusion matrices, ROC curves, feature importance\n",
    "- Store custom visualizations and reports\n",
    "- Implement artifact versioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054394c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 - Advanced Feature Implementation (Hasan)\n",
    "# - Implement model registration and versioning steps\n",
    "# - Prepare serving scripts and simple endpoint tests\n",
    "# - Add utilities to log artifacts (plots, metrics) to MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f347598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 2: ADVANCED FEATURE IMPLEMENTATION\n",
      "======================================================================\n",
      "\n",
      "âœ“ Connected to MLflow server: http://127.0.0.1:5000\n",
      "âœ“ Data loaded and split\n"
     ]
    }
   ],
   "source": [
    "# Phase 2.1 - Setup and Imports\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PHASE 2: ADVANCED FEATURE IMPLEMENTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Set tracking URI\n",
    "TRACKING_URI = 'http://127.0.0.1:5000'\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "\n",
    "print(f\"\\nâœ“ Connected to MLflow server: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Load and prepare data\n",
    "iris = load_iris(as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"âœ“ Data loaded and split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "864ab1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 15:47:48 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PART 2.1: MODEL REGISTRY & VERSIONING\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 15:47:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'IrisClassifier' already exists. Creating a new version of this model...\n",
      "2025/11/12 15:47:52 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IrisClassifier, version 7\n",
      "Created version '7' of model 'IrisClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Registered IrisClassifier version 1 - Accuracy: 1.0000\n",
      "ğŸƒ View run version_1 at: http://127.0.0.1:5000/#/experiments/244918341474380135/runs/554f0ed841034cdd819d3d3bfe059f17\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/244918341474380135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 15:47:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 15:47:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'IrisClassifier' already exists. Creating a new version of this model...\n",
      "2025/11/12 15:47:57 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IrisClassifier, version 8\n",
      "Created version '8' of model 'IrisClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Registered IrisClassifier version 2 - Accuracy: 1.0000\n",
      "ğŸƒ View run version_2 at: http://127.0.0.1:5000/#/experiments/244918341474380135/runs/24bf69c8975b44269f979167533c7caa\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/244918341474380135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/12 15:47:57 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/12 15:48:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'IrisClassifier' already exists. Creating a new version of this model...\n",
      "2025/11/12 15:48:01 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IrisClassifier, version 9\n",
      "Created version '9' of model 'IrisClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Registered IrisClassifier version 3 - Accuracy: 1.0000\n",
      "ğŸƒ View run version_3 at: http://127.0.0.1:5000/#/experiments/244918341474380135/runs/77b6e5a305e646b19b1163901110f8bc\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/244918341474380135\n",
      "\n",
      "âœ“ Total versions registered: 3\n"
     ]
    }
   ],
   "source": [
    "# Phase 2.2 - Model Registry & Versioning\n",
    "# Train and register multiple model versions\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2.1: MODEL REGISTRY & VERSIONING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "mlflow.set_experiment(\"Model Registry Demo\")\n",
    "model_name = \"IrisClassifier\"\n",
    "registered_versions = []\n",
    "\n",
    "model_configs = [\n",
    "    {\"n_estimators\": 10, \"max_depth\": 3, \"description\": \"Baseline model v1\"},\n",
    "    {\"n_estimators\": 50, \"max_depth\": 5, \"description\": \"Improved model v2\"},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 10, \"description\": \"Best model v3\"}\n",
    "]\n",
    "\n",
    "for i, config in enumerate(model_configs, 1):\n",
    "    with mlflow.start_run(run_name=f\"version_{i}\"):\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=config['n_estimators'],\n",
    "            max_depth=config['max_depth'],\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "        mlflow.log_params(config)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        \n",
    "        model_info = mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            artifact_path=\"model\",\n",
    "            registered_model_name=model_name\n",
    "        )\n",
    "        \n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        registered_versions.append({\n",
    "            \"version\": i,\n",
    "            \"run_id\": run_id,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"config\": config\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ“ Registered {model_name} version {i} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(f\"\\nâœ“ Total versions registered: {len(registered_versions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "475fe7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7assa\\AppData\\Local\\Temp\\ipykernel_13736\\1979799679.py:10: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PART 2.2: STAGE TRANSITION WORKFLOWS\n",
      "======================================================================\n",
      "ğŸ”„ Transitioning Version 1 â†’ Staging\n",
      "âœ“ Version 1 is now in Staging\n",
      "\n",
      "ğŸ”„ Transitioning Version 2 â†’ Staging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7assa\\AppData\\Local\\Temp\\ipykernel_13736\\1979799679.py:21: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Version 2 is now in Staging (Version 1 archived)\n",
      "\n",
      "ğŸ”„ Transitioning Version 3 â†’ Production\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7assa\\AppData\\Local\\Temp\\ipykernel_13736\\1979799679.py:32: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Version 3 is now in Production\n",
      "\n",
      "### Model Stage Summary ###\n",
      "\n",
      "  Archived: Versions ['1']\n",
      "  None: Versions ['9', '8', '7', '6', '5', '4']\n",
      "  Production: Versions ['3']\n",
      "  Staging: Versions ['2']\n"
     ]
    }
   ],
   "source": [
    "# Phase 2.3 - Stage Transition Workflows\n",
    "# Move models through stages: None â†’ Staging â†’ Production\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2.2: STAGE TRANSITION WORKFLOWS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Transition version 1 to Staging\n",
    "print(\"ğŸ”„ Transitioning Version 1 â†’ Staging\")\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name, version=1, stage=\"Staging\", archive_existing_versions=False\n",
    ")\n",
    "client.update_model_version(\n",
    "    name=model_name, version=1,\n",
    "    description=\"Initial baseline model in staging for testing\"\n",
    ")\n",
    "print(\"âœ“ Version 1 is now in Staging\")\n",
    "\n",
    "# Transition version 2 to Staging (archive v1)\n",
    "print(\"\\nğŸ”„ Transitioning Version 2 â†’ Staging\")\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name, version=2, stage=\"Staging\", archive_existing_versions=True\n",
    ")\n",
    "client.update_model_version(\n",
    "    name=model_name, version=2,\n",
    "    description=\"Improved model, testing in staging\"\n",
    ")\n",
    "print(\"âœ“ Version 2 is now in Staging (Version 1 archived)\")\n",
    "\n",
    "# Promote version 3 to Production\n",
    "print(\"\\nğŸ”„ Transitioning Version 3 â†’ Production\")\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name, version=3, stage=\"Production\", archive_existing_versions=False\n",
    ")\n",
    "client.update_model_version(\n",
    "    name=model_name, version=3,\n",
    "    description=\"Best performing model - deployed to production\"\n",
    ")\n",
    "print(\"âœ“ Version 3 is now in Production\")\n",
    "\n",
    "# Display stage summary\n",
    "print(\"\\n### Model Stage Summary ###\\n\")\n",
    "versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "stage_summary = {}\n",
    "for v in versions:\n",
    "    stage = v.current_stage\n",
    "    version = v.version\n",
    "    if stage not in stage_summary:\n",
    "        stage_summary[stage] = []\n",
    "    stage_summary[stage].append(version)\n",
    "\n",
    "for stage, versions_list in sorted(stage_summary.items()):\n",
    "    print(f\"  {stage}: Versions {versions_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d79d716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PART 2.3: ARTIFACT MANAGEMENT\n",
      "======================================================================\n",
      "âœ“ Logged metrics: Accuracy=1.0000\n",
      "âœ“ Logged confusion matrix\n",
      "âœ“ Logged feature importance\n",
      "âœ“ Logged classification report\n",
      "âœ“ Logged model metadata\n",
      "ğŸƒ View run production_model_artifacts at: http://127.0.0.1:5000/#/experiments/244918341474380135/runs/4599a24f8d3f4b85bb9c3c1cb4263c1a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/244918341474380135\n",
      "\n",
      "âœ“ All artifacts logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "# Phase 2.4 - Artifact Management\n",
    "# Log confusion matrix, feature importance, reports\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2.3: ARTIFACT MANAGEMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "with mlflow.start_run(run_name=\"production_model_artifacts\"):\n",
    "    # Load production model\n",
    "    model_uri = f\"models:/{model_name}/Production\"\n",
    "    model = mlflow.sklearn.load_model(model_uri)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Log metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    mlflow.log_metrics(metrics)\n",
    "    print(f\"âœ“ Logged metrics: Accuracy={metrics['accuracy']:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "    plt.title('Confusion Matrix - Production Model')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    cm_path = 'model_artifacts/confusion_matrix.png'\n",
    "    plt.savefig(cm_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(cm_path)\n",
    "    print(f\"âœ“ Logged confusion matrix\")\n",
    "    \n",
    "    # Feature Importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': iris.feature_names,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Feature Importance - Production Model')\n",
    "    plt.gca().invert_yaxis()\n",
    "    fi_path = 'model_artifacts/feature_importance.png'\n",
    "    plt.savefig(fi_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(fi_path)\n",
    "    print(f\"âœ“ Logged feature importance\")\n",
    "    \n",
    "    # Classification Report\n",
    "    report = classification_report(y_test, y_pred, \n",
    "                                   target_names=iris.target_names, output_dict=True)\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    report_path = 'model_artifacts/classification_report.csv'\n",
    "    report_df.to_csv(report_path)\n",
    "    mlflow.log_artifact(report_path)\n",
    "    print(f\"âœ“ Logged classification report\")\n",
    "    \n",
    "    # Model Metadata JSON\n",
    "    metadata = {\n",
    "        \"model_name\": model_name,\n",
    "        \"version\": \"3 (Production)\",\n",
    "        \"training_date\": datetime.now().isoformat(),\n",
    "        \"framework\": \"scikit-learn\",\n",
    "        \"algorithm\": \"RandomForestClassifier\",\n",
    "        \"metrics\": metrics,\n",
    "        \"feature_names\": iris.feature_names,\n",
    "        \"target_names\": iris.target_names.tolist(),\n",
    "        \"n_samples_train\": len(X_train),\n",
    "        \"n_samples_test\": len(X_test)\n",
    "    }\n",
    "    metadata_path = 'model_artifacts/model_metadata.json'\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    mlflow.log_artifact(metadata_path)\n",
    "    print(f\"âœ“ Logged model metadata\")\n",
    "\n",
    "print(\"\\nâœ“ All artifacts logged to MLflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddf10f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PART 2.4: MODEL SERVING & BATCH INFERENCE\n",
      "======================================================================\n",
      "âœ“ Created serving instructions\n",
      "âœ“ Created batch inference script\n",
      "\n",
      "### Testing Batch Inference ###\n",
      "\n",
      "Batch Inference Results:\n",
      "--------------------------------------------------\n",
      "Sample 1: setosa (confidence: 100.0%)\n",
      "Sample 2: virginica (confidence: 96.0%)\n",
      "Sample 3: virginica (confidence: 66.0%)\n"
     ]
    }
   ],
   "source": [
    "# Phase 2.5 - Model Serving & Batch Inference\n",
    "# Create deployment scripts and test batch predictions\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2.4: MODEL SERVING & BATCH INFERENCE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create serving instructions\n",
    "serving_script = \"\"\"\n",
    "# Model Serving Instructions\n",
    "# mlflow models serve -m models:/IrisClassifier/Production -p 5001 --no-conda\n",
    "# curl -X POST -H \"Content-Type: application/json\" \\\\\n",
    "#      --data '{\"dataframe_split\": {\"columns\": [\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"], \"data\": [[5.1, 3.5, 1.4, 0.2]]}}' \\\\\n",
    "#      http://127.0.0.1:5001/invocations\n",
    "\"\"\"\n",
    "with open('deployment/serving_instructions.txt', 'w') as f:\n",
    "    f.write(serving_script)\n",
    "print(\"âœ“ Created serving instructions\")\n",
    "\n",
    "# Batch inference script\n",
    "inference_script = \"\"\"import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "model = mlflow.sklearn.load_model(\"models:/IrisClassifier/Production\")\n",
    "data = pd.DataFrame({\n",
    "    'sepal length (cm)': [5.1, 6.2, 5.9],\n",
    "    'sepal width (cm)': [3.5, 3.4, 3.0],\n",
    "    'petal length (cm)': [1.4, 5.4, 5.1],\n",
    "    'petal width (cm)': [0.2, 2.3, 1.8]\n",
    "})\n",
    "predictions = model.predict(data)\n",
    "print(\"Predictions:\", predictions)\n",
    "\"\"\"\n",
    "with open('deployment/batch_inference.py', 'w') as f:\n",
    "    f.write(inference_script)\n",
    "print(\"âœ“ Created batch inference script\")\n",
    "\n",
    "# Test batch inference\n",
    "print(\"\\n### Testing Batch Inference ###\\n\")\n",
    "prod_model = mlflow.sklearn.load_model(f\"models:/{model_name}/Production\")\n",
    "\n",
    "test_samples = pd.DataFrame({\n",
    "    'sepal length (cm)': [5.1, 6.7, 4.9],\n",
    "    'sepal width (cm)': [3.5, 3.0, 2.5],\n",
    "    'petal length (cm)': [1.4, 5.2, 4.5],\n",
    "    'petal width (cm)': [0.2, 2.3, 1.7]\n",
    "})\n",
    "\n",
    "predictions = prod_model.predict(test_samples)\n",
    "probabilities = prod_model.predict_proba(test_samples)\n",
    "\n",
    "print(\"Batch Inference Results:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (pred, probs) in enumerate(zip(predictions, probabilities)):\n",
    "    pred_name = iris.target_names[pred]\n",
    "    confidence = probs[pred] * 100\n",
    "    print(f\"Sample {i+1}: {pred_name} (confidence: {confidence:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0689c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PART 2.5: DOCKER DEPLOYMENT (OPTIONAL)\n",
      "======================================================================\n",
      "âœ“ Using existing model_name: IrisClassifier\n",
      "âœ“ Created improved Dockerfile\n",
      "âœ“ Created Docker commands\n",
      "âš ï¸  Docker deployment is OPTIONAL\n",
      "\n",
      "======================================================================\n",
      "âœ“ PHASE 2 COMPLETE: ADVANCED FEATURE IMPLEMENTATION\n",
      "======================================================================\n",
      "\n",
      "PHASE 2 DELIVERABLES:\n",
      "âœ“ Model Registry: 3 versions registered (if cells 2.1-2.5 were run)\n",
      "âœ“ Stage Transitions: Version 3 in Production\n",
      "âœ“ Artifacts: Confusion matrix, feature importance, reports\n",
      "âœ“ Deployment Files: Serving scripts, batch inference, Dockerfile\n",
      "âœ“ Testing: Batch inference validated\n",
      "\n",
      "FILES CREATED:\n",
      "\n",
      "âœ“ model_artifacts/confusion_matrix.png\n",
      "âœ“ model_artifacts/feature_importance.png\n",
      "âœ“ model_artifacts/classification_report.csv\n",
      "âœ“ model_artifacts/model_metadata.json\n",
      "âœ“ deployment/serving_instructions.txt\n",
      "âœ“ deployment/batch_inference.py\n",
      "âœ“ deployment/Dockerfile\n",
      "âœ“ deployment/docker_commands.txt\n",
      "\n",
      "âœ“ Phase 2 summary saved to: phase2_completion_notes.txt\n",
      "\n",
      "ğŸ‰ Phase 2 Implementation Complete!\n"
     ]
    }
   ],
   "source": [
    "# Phase 2.6 - Docker Deployment & Phase 2 Summary\n",
    "# (OPTIONAL: Docker files for documentation)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PART 2.5: DOCKER DEPLOYMENT (OPTIONAL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define model_name if not already defined (standalone execution support)\n",
    "try:\n",
    "    model_name\n",
    "    print(f\"âœ“ Using existing model_name: {model_name}\")\n",
    "except NameError:\n",
    "    model_name = \"IrisClassifier\"\n",
    "    print(f\"âš ï¸  model_name not defined, using default: {model_name}\")\n",
    "\n",
    "# Improved Dockerfile with better error handling\n",
    "dockerfile_content = f\"\"\"FROM python:3.9-slim\n",
    "\n",
    "# Upgrade pip to avoid installation issues\n",
    "RUN pip install --upgrade pip\n",
    "\n",
    "# Install dependencies with verbose output and no cache\n",
    "RUN pip install --no-cache-dir --verbose \\\n",
    "    mlflow \\\n",
    "    scikit-learn \\\n",
    "    pandas \\\n",
    "    numpy\n",
    "\n",
    "# Set working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy MLflow runs directory\n",
    "COPY ./mlruns ./mlruns\n",
    "\n",
    "# Expose port\n",
    "EXPOSE 5001\n",
    "\n",
    "# Serve model\n",
    "CMD [\"mlflow\", \"models\", \"serve\", \"-m\", \"models:/{model_name}/Production\", \"-p\", \"5001\", \"--host\", \"0.0.0.0\", \"--no-conda\"]\n",
    "\"\"\"\n",
    "\n",
    "# Ensure deployment directory exists\n",
    "import os\n",
    "os.makedirs('deployment', exist_ok=True)\n",
    "\n",
    "# Write Dockerfile\n",
    "with open('deployment/Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile_content)\n",
    "print(\"âœ“ Created improved Dockerfile\")\n",
    "\n",
    "# Docker commands\n",
    "docker_commands = \"\"\"\n",
    "# Docker Deployment Commands\n",
    "docker build -t iris-classifier:v1 -f deployment/Dockerfile .\n",
    "docker run -p 5001:5001 iris-classifier:v1\n",
    "\"\"\"\n",
    "with open('deployment/docker_commands.txt', 'w') as f:\n",
    "    f.write(docker_commands)\n",
    "print(\"âœ“ Created Docker commands\")\n",
    "print(\"âš ï¸  Docker deployment is OPTIONAL\\n\")\n",
    "\n",
    "# Phase 2 Summary\n",
    "print(\"=\"*70)\n",
    "print(\"âœ“ PHASE 2 COMPLETE: ADVANCED FEATURE IMPLEMENTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = f\"\"\"\n",
    "PHASE 2 DELIVERABLES:\n",
    "âœ“ Model Registry: 3 versions registered (if cells 2.1-2.5 were run)\n",
    "âœ“ Stage Transitions: Version 3 in Production\n",
    "âœ“ Artifacts: Confusion matrix, feature importance, reports\n",
    "âœ“ Deployment Files: Serving scripts, batch inference, Dockerfile\n",
    "âœ“ Testing: Batch inference validated\n",
    "\n",
    "FILES CREATED:\n",
    "\"\"\"\n",
    "\n",
    "created_files = [\n",
    "    'model_artifacts/confusion_matrix.png',\n",
    "    'model_artifacts/feature_importance.png',\n",
    "    'model_artifacts/classification_report.csv',\n",
    "    'model_artifacts/model_metadata.json',\n",
    "    'deployment/serving_instructions.txt',\n",
    "    'deployment/batch_inference.py',\n",
    "    'deployment/Dockerfile',\n",
    "    'deployment/docker_commands.txt'\n",
    "]\n",
    "\n",
    "for file in created_files:\n",
    "    exists = \"âœ“\" if os.path.exists(file) else \"âœ—\"\n",
    "    summary += f\"\\n{exists} {file}\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "with open('phase2_completion_notes.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(summary)\n",
    "print(\"\\nâœ“ Phase 2 summary saved to: phase2_completion_notes.txt\")\n",
    "print(\"\\nğŸ‰ Phase 2 Implementation Complete!\")\n",
    "\n",
    "# Display note about full execution\n",
    "if not os.path.exists('model_artifacts/confusion_matrix.png'):\n",
    "    print(\"\\n\" + \"âš ï¸  WARNING: Some artifacts are missing.\")\n",
    "    print(\"   For complete Phase 2 deliverables, run all cells 2.1 â†’ 2.6 in order.\")\n",
    "    print(\"   This ensures model registration, artifacts, and serving scripts are created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8caba3",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Nawaf Al Harthi - Research, Analysis & Integration\n",
    "\n",
    "#### **Phase 1: Competitive Analysis**\n",
    "\n",
    "1. **Framework Comparison Research**\n",
    "\n",
    "- Deep comparison: MLflow vs. Kubeflow vs. Weights & Biases\n",
    "- Feature comparison matrix\n",
    "- Use case suitability analysis\n",
    "\n",
    "2. **Integration Planning**\n",
    "\n",
    "- Design demo workflow that integrates all components\n",
    "- Plan presentation narrative and flow\n",
    "- Create evaluation criteria for critical analysis\n",
    "\n",
    "#### **Phase 2: Integration & Quality Assurance**\n",
    "\n",
    "1. **End-to-End Workflow Integration**\n",
    "\n",
    "- Combine tracking with registry and serving components\n",
    "- Create comprehensive demo scenario\n",
    "- Ensure seamless handoffs between components\n",
    "\n",
    "2. **Testing & Validation**\n",
    "\n",
    "- Validate all MLflow components work together\n",
    "- Test edge cases and error handling\n",
    "- Performance validation across different scenarios\n",
    "\n",
    "3. **Documentation & Best Practices**\n",
    "\n",
    "- Create installation and troubleshooting guide\n",
    "- Document team workflows and collaboration patterns\n",
    "- Prepare code documentation and comments\n",
    "\n",
    "#### **Phase 3: Critical Analysis & Presentation**\n",
    "\n",
    "1. **Comprehensive Evaluation**\n",
    "\n",
    "- Analyze MLflow strengths and weaknesses\n",
    "- Compare with alternative tools\n",
    "- Provide improvement recommendations\n",
    "\n",
    "---\n",
    "\n",
    "### **Additional Tasks:**\n",
    "- Comprehensive tool comparison\n",
    "- End-to-end workflow integration testing\n",
    "- Quality assurance across all components\n",
    "- Documentation and best practices guide\n",
    "- Presentation narrative and demo script coordination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17ce762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 - Competitive Analysis (Nawaf)\n",
    "# - Create a comparison matrix for MLflow, Kubeflow, and W&B\n",
    "# - Capture features, strengths, and limitations for each\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4191fb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 - Integration & Quality Assurance (Nawaf)\n",
    "# - Draft end-to-end demo steps that wire tracking -> registry -> serving\n",
    "# - Write basic validation checks and error handling tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7238fec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3 - Critical Analysis & Presentation (Nawaf)\n",
    "# - Summarize findings, recommendations, and demo scripts\n",
    "# - Prepare presentation notes and rehearsal checklist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f95ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0762c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
