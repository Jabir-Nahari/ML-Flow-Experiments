{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Test Notebook\n",
    "\n",
    "This notebook runs key components from the MLflow evaluation project.\n",
    "\n",
    "**Prerequisites:**\n",
    "- MLflow server running on http://127.0.0.1:5000\n",
    "- Required packages installed (mlflow, scikit-learn, pandas, seaborn, matplotlib)\n",
    "\n",
    "**Run this notebook cell by cell to test the complete MLflow workflow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: http://127.0.0.1:5000\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Set tracking URI\n",
    "TRACKING_URI = 'http://127.0.0.1:5000'\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic dataset loaded successfully\n",
      "Data loading completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Data\n",
    "iris = load_iris(as_frame=True)\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "wine = load_wine(as_frame=True)\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "# Titanic data\n",
    "try:\n",
    "    titanic = sns.load_dataset('titanic')\n",
    "    titanic = titanic.dropna(subset=['survived'])\n",
    "    titanic = titanic.select_dtypes(include=['number']).fillna(0)\n",
    "    X_titanic = titanic.drop(columns=['survived'])\n",
    "    y_titanic = titanic['survived']\n",
    "    print(\"Titanic dataset loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Titanic dataset not available: {e}\")\n",
    "    X_titanic = None\n",
    "    y_titanic = None\n",
    "\n",
    "print(\"Data loading completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training function defined\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Define Training Function\n",
    "def train_and_log_baselines(X, y, dataset_name='dataset', seed=42):\n",
    "    experiment_name = f\"{dataset_name} experiment\"\n",
    "    try:\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        print(f'Warning: could not set experiment \"{experiment_name}\": {e}')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    models = {\n",
    "        'random_forest': RandomForestClassifier(random_state=seed),\n",
    "        'logistic_regression': LogisticRegression(max_iter=500)\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.log_param('model', name)\n",
    "            mlflow.log_param('dataset', dataset_name)\n",
    "            mlflow.log_param('seed', seed)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            mlflow.log_metrics({'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1})\n",
    "\n",
    "            try:\n",
    "                input_example = X_train.head(5)\n",
    "                sample_preds = model.predict(input_example)\n",
    "                signature = infer_signature(input_example, sample_preds)\n",
    "                mlflow.sklearn.log_model(model, artifact_path='artifacts', signature=signature, input_example=input_example)\n",
    "            except Exception as e:\n",
    "                print(f\"Model logging failed: {e}\")\n",
    "                try:\n",
    "                    mlflow.sklearn.log_model(model, artifact_path='artifacts')\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seeds for testing: [6258, 1483, 7554]\n",
      "Warning: could not set experiment \"iris experiment\": API request to endpoint /api/2.0/mlflow/experiments/get-by-name failed with error code 403 != 200. Response body: ''\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "API request to endpoint /api/2.0/mlflow/runs/create failed with error code 403 != 200. Response body: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Train baselines\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mtrain_and_log_baselines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_iris\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_iris\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43miris\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m X_titanic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     10\u001b[39m         train_and_log_baselines(X_titanic, y_titanic, dataset_name=\u001b[33m'\u001b[39m\u001b[33mtitanic\u001b[39m\u001b[33m'\u001b[39m, seed=seed)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtrain_and_log_baselines\u001b[39m\u001b[34m(X, y, dataset_name, seed)\u001b[39m\n\u001b[32m     11\u001b[39m models = {\n\u001b[32m     12\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mrandom_forest\u001b[39m\u001b[33m'\u001b[39m: RandomForestClassifier(random_state=seed),\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlogistic_regression\u001b[39m\u001b[33m'\u001b[39m: LogisticRegression(max_iter=\u001b[32m500\u001b[39m)\n\u001b[32m     14\u001b[39m }\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[32m     18\u001b[39m         mlflow.log_param(\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m, name)\n\u001b[32m     19\u001b[39m         mlflow.log_param(\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m, dataset_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ICS 474/ML-Flow-Experiments Jabir/.venv/lib/python3.13/site-packages/mlflow/tracking/fluent.py:478\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    474\u001b[39m         user_specified_tags[MLFLOW_RUN_NAME] = run_name\n\u001b[32m    476\u001b[39m     resolved_tags = context_registry.resolve_tags(user_specified_tags)\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m     active_run_obj = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexp_id_for_run\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolved_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m log_system_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    485\u001b[39m     \u001b[38;5;66;03m# If `log_system_metrics` is not specified, we will check environment variable.\u001b[39;00m\n\u001b[32m    486\u001b[39m     log_system_metrics = MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING.get()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ICS 474/ML-Flow-Experiments Jabir/.venv/lib/python3.13/site-packages/mlflow/tracking/client.py:479\u001b[39m, in \u001b[36mMlflowClient.create_run\u001b[39m\u001b[34m(self, experiment_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_run\u001b[39m(\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    427\u001b[39m     experiment_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    430\u001b[39m     run_name: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    431\u001b[39m ) -> Run:\n\u001b[32m    432\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    Create a :py:class:`mlflow.entities.Run` object that can be associated with\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[33;03m    metrics, parameters, artifacts, etc.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    477\u001b[39m \u001b[33;03m        status: RUNNING\u001b[39;00m\n\u001b[32m    478\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tracking_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ICS 474/ML-Flow-Experiments Jabir/.venv/lib/python3.13/site-packages/mlflow/telemetry/track.py:30\u001b[39m, in \u001b[36mrecord_usage_event.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m start_time = time.time()\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result  \u001b[38;5;66;03m# noqa: RET504\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ICS 474/ML-Flow-Experiments Jabir/.venv/lib/python3.13/site-packages/mlflow/tracking/_tracking_service/client.py:183\u001b[39m, in \u001b[36mTrackingServiceClient.create_run\u001b[39m\u001b[34m(self, experiment_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# Extract user from tags\u001b[39;00m\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# This logic is temporary; the user_id attribute of runs is deprecated and will be removed\u001b[39;00m\n\u001b[32m    180\u001b[39m \u001b[38;5;66;03m# in a later release.\u001b[39;00m\n\u001b[32m    181\u001b[39m user_id = tags.get(MLFLOW_USER, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mget_current_time_millis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRunTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ICS 474/ML-Flow-Experiments Jabir/.venv/lib/python3.13/site-packages/mlflow/store/tracking/rest_store.py:340\u001b[39m, in \u001b[36mRestStore.create_run\u001b[39m\u001b[34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[39m\n\u001b[32m    330\u001b[39m tag_protos = [tag.to_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags]\n\u001b[32m    331\u001b[39m req_body = message_to_json(\n\u001b[32m    332\u001b[39m     CreateRun(\n\u001b[32m    333\u001b[39m         experiment_id=\u001b[38;5;28mstr\u001b[39m(experiment_id),\n\u001b[32m   (...)\u001b[39m\u001b[32m    338\u001b[39m     )\n\u001b[32m    339\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateRun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Run.from_proto(response_proto.run)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ICS 474/ML-Flow-Experiments Jabir/.venv/lib/python3.13/site-packages/mlflow/store/tracking/rest_store.py:203\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint, retry_timeout_seconds, response_proto)\u001b[39m\n\u001b[32m    201\u001b[39m     endpoint, method = \u001b[38;5;28mself\u001b[39m._METHOD_TO_INFO[api]\n\u001b[32m    202\u001b[39m response_proto = response_proto \u001b[38;5;129;01mor\u001b[39;00m api.Response()\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ICS 474/ML-Flow-Experiments Jabir/.venv/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:596\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[39m\n\u001b[32m    593\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m    594\u001b[39m     response = http_request(**call_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m response = \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m response_to_parse = response.text\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ICS 474/ML-Flow-Experiments Jabir/.venv/lib/python3.13/site-packages/mlflow/utils/rest_utils.py:321\u001b[39m, in \u001b[36mverify_rest_response\u001b[39m\u001b[34m(response, endpoint)\u001b[39m\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    317\u001b[39m         base_msg = (\n\u001b[32m    318\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != 200\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    320\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    322\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Response body: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    323\u001b[39m             error_code=get_error_code(response.status_code),\n\u001b[32m    324\u001b[39m         )\n\u001b[32m    326\u001b[39m \u001b[38;5;66;03m# Skip validation for endpoints (e.g. DBFS file-download API) which may return a non-JSON\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;66;03m# response\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint.startswith(_REST_API_PATH_PREFIX) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _can_parse_as_json_object(response.text):\n",
      "\u001b[31mMlflowException\u001b[39m: API request to endpoint /api/2.0/mlflow/runs/create failed with error code 403 != 200. Response body: ''"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train Baseline Models\n",
    "# Generate seeds\n",
    "seeds = [random.randint(0, 10000) for _ in range(3)]\n",
    "print(f'Using seeds for testing: {seeds}')\n",
    "\n",
    "# Train baselines\n",
    "for seed in seeds:\n",
    "    train_and_log_baselines(X_iris, y_iris, dataset_name='iris', seed=seed)\n",
    "    if X_titanic is not None:\n",
    "        train_and_log_baselines(X_titanic, y_titanic, dataset_name='titanic', seed=seed)\n",
    "    train_and_log_baselines(X_wine, y_wine, dataset_name='wine', seed=seed)\n",
    "\n",
    "print(\"Baseline training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/15 12:53:14 INFO mlflow.tracking.fluent: Experiment with name 'Model Registry Demo' does not exist. Creating a new experiment.\n",
      "\u001b[31m2025/11/15 12:53:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'IrisClassifier'.\n",
      "2025/11/15 12:53:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IrisClassifier, version 1\n",
      "Created version '1' of model 'IrisClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered IrisClassifier version 1 - Accuracy: 1.0000\n",
      "üèÉ View run version_1 at: http://127.0.0.1:5000/#/experiments/4/runs/798237ddc61b4a2a9a7decf45d986036\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/15 12:53:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'IrisClassifier' already exists. Creating a new version of this model...\n",
      "2025/11/15 12:53:17 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IrisClassifier, version 2\n",
      "Created version '2' of model 'IrisClassifier'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered IrisClassifier version 2 - Accuracy: 1.0000\n",
      "üèÉ View run version_2 at: http://127.0.0.1:5000/#/experiments/4/runs/e167926cd79e411f9bf64b7725e900d8\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/15 12:53:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'IrisClassifier' already exists. Creating a new version of this model...\n",
      "2025/11/15 12:53:19 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: IrisClassifier, version 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered IrisClassifier version 3 - Accuracy: 1.0000\n",
      "üèÉ View run version_3 at: http://127.0.0.1:5000/#/experiments/4/runs/0b004a1f961a47818645d9e7e4e72249\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/4\n",
      "Model versions registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'IrisClassifier'.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Model Registry - Train and Register Versions\n",
    "mlflow.set_experiment(\"Model Registry Demo\")\n",
    "model_name = \"IrisClassifier\"\n",
    "\n",
    "model_configs = [\n",
    "    {\"n_estimators\": 10, \"max_depth\": 3},\n",
    "    {\"n_estimators\": 50, \"max_depth\": 5},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 10}\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)\n",
    "\n",
    "for i, config in enumerate(model_configs, 1):\n",
    "    with mlflow.start_run(run_name=f\"version_{i}\"):\n",
    "        model = RandomForestClassifier(n_estimators=config['n_estimators'], max_depth=config['max_depth'], random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        mlflow.log_params(config)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        \n",
    "        model_info = mlflow.sklearn.log_model(model, registered_model_name=model_name)\n",
    "        print(f\"Registered {model_name} version {i} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"Model versions registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1 moved to Staging\n",
      "Version 2 moved to Staging (Version 1 archived)\n",
      "Version 3 moved to Production\n",
      "Stage transitions completed\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Stage Transitions\n",
    "# Transition version 1 to Staging\n",
    "client.transition_model_version_stage(name=model_name, version=1, stage=\"Staging\")\n",
    "print(\"Version 1 moved to Staging\")\n",
    "\n",
    "# Transition version 2 to Staging (archive v1)\n",
    "client.transition_model_version_stage(name=model_name, version=2, stage=\"Staging\", archive_existing_versions=True)\n",
    "print(\"Version 2 moved to Staging (Version 1 archived)\")\n",
    "\n",
    "# Promote version 3 to Production\n",
    "client.transition_model_version_stage(name=model_name, version=3, stage=\"Production\")\n",
    "print(\"Version 3 moved to Production\")\n",
    "\n",
    "print(\"Stage transitions completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Create Directories and Load Production Model\n",
    "# Create directories\n",
    "os.makedirs('./artifacts', exist_ok=True)\n",
    "os.makedirs('./deployment', exist_ok=True)\n",
    "\n",
    "# Load production model\n",
    "model_uri = f\"models:/{model_name}/Production\"\n",
    "prod_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "y_pred = prod_model.predict(X_test)\n",
    "y_pred_proba = prod_model.predict_proba(X_test)\n",
    "\n",
    "print(\"Production model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix saved and logged\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Generate and Log Artifacts - Confusion Matrix\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title('Confusion Matrix - Production Model')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix.png', bbox_inches='tight', dpi=150)\n",
    "mlflow.log_artifact('confusion_matrix.png')\n",
    "os.remove('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Confusion matrix saved and logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance plot saved and logged\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Generate and Log Artifacts - Feature Importance\n",
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': iris.feature_names,\n",
    "    'importance': prod_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance - Production Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig('feature_importance.png', bbox_inches='tight', dpi=150)\n",
    "plt.close()\n",
    "mlflow.log_artifact('feature_importance.png')\n",
    "os.remove('feature_importance.png')\n",
    "\n",
    "print(\"Feature importance plot saved and logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report and metadata saved and logged\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Generate and Log Artifacts - Classification Report and Metadata\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred, target_names=iris.target_names, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv('classification_report.csv')\n",
    "mlflow.log_artifact('classification_report.csv')\n",
    "os.remove('classification_report.csv')\n",
    "\n",
    "# Model Metadata\n",
    "metadata = {\n",
    "    \"model_name\": model_name,\n",
    "    \"version\": \"3 (Production)\",\n",
    "    \"training_date\": datetime.now().isoformat(),\n",
    "    \"framework\": \"scikit-learn\",\n",
    "    \"algorithm\": \"RandomForestClassifier\",\n",
    "    \"metrics\": {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    },\n",
    "    \"feature_names\": iris.feature_names,\n",
    "    \"target_names\": iris.target_names.tolist(),\n",
    "    \"n_samples_train\": len(X_train),\n",
    "    \"n_samples_test\": len(X_test)\n",
    "}\n",
    "with open('model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "mlflow.log_artifact('model_metadata.json')\n",
    "os.remove('model_metadata.json')\n",
    "\n",
    "print(\"Classification report and metadata saved and logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Inference Results:\n",
      "--------------------------------------------------\n",
      "Sample 1: setosa (confidence: 100.0%)\n",
      "Sample 2: virginica (confidence: 96.0%)\n",
      "Sample 3: virginica (confidence: 66.0%)\n",
      "\n",
      "Batch inference test completed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Batch Inference Test\n",
    "test_samples = pd.DataFrame({\n",
    "    'sepal length (cm)': [5.1, 6.7, 4.9],\n",
    "    'sepal width (cm)': [3.5, 3.0, 2.5],\n",
    "    'petal length (cm)': [1.4, 5.2, 4.5],\n",
    "    'petal width (cm)': [0.2, 2.3, 1.7]\n",
    "})\n",
    "\n",
    "predictions = prod_model.predict(test_samples)\n",
    "probabilities = prod_model.predict_proba(test_samples)\n",
    "\n",
    "print(\"Batch Inference Results:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (pred, probs) in enumerate(zip(predictions, probabilities)):\n",
    "    pred_name = iris.target_names[pred]\n",
    "    confidence = probs[pred] * 100\n",
    "    print(f\"Sample {i+1}: {pred_name} (confidence: {confidence:.1f}%)\")\n",
    "\n",
    "print(\"\\nBatch inference test completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
