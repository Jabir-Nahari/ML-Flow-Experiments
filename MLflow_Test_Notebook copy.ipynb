{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Test Notebook\n",
    "\n",
    "This notebook runs key components from the MLflow evaluation project.\n",
    "\n",
    "**Prerequisites:**\n",
    "- MLflow server running on http://127.0.0.1:5000\n",
    "- Required packages installed (mlflow, scikit-learn, pandas, seaborn, matplotlib)\n",
    "\n",
    "**Run this notebook cell by cell to test the complete MLflow workflow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and Imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Set tracking URI\n",
    "TRACKING_URI = 'http://127.0.0.1:5000'\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "client = MlflowClient()\n",
    "\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load Data\n",
    "iris = load_iris(as_frame=True)\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "wine = load_wine(as_frame=True)\n",
    "X_wine = wine.data\n",
    "y_wine = wine.target\n",
    "\n",
    "# Titanic data\n",
    "try:\n",
    "    titanic = sns.load_dataset('titanic')\n",
    "    titanic = titanic.dropna(subset=['survived'])\n",
    "    titanic = titanic.select_dtypes(include=['number']).fillna(0)\n",
    "    X_titanic = titanic.drop(columns=['survived'])\n",
    "    y_titanic = titanic['survived']\n",
    "    print(\"Titanic dataset loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Titanic dataset not available: {e}\")\n",
    "    X_titanic = None\n",
    "    y_titanic = None\n",
    "\n",
    "print(\"Data loading completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define Training Function\n",
    "def train_and_log_baselines(X, y, dataset_name='dataset', seed=42):\n",
    "    experiment_name = f\"{dataset_name} experiment\"\n",
    "    try:\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        print(f'Warning: could not set experiment \"{experiment_name}\": {e}')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    models = {\n",
    "        'random_forest': RandomForestClassifier(random_state=seed),\n",
    "        'logistic_regression': LogisticRegression(max_iter=500)\n",
    "    }\n",
    "\n",
    "    for name, model in models.items():\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.log_param('model', name)\n",
    "            mlflow.log_param('dataset', dataset_name)\n",
    "            mlflow.log_param('seed', seed)\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            mlflow.log_metrics({'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1})\n",
    "\n",
    "            try:\n",
    "                input_example = X_train.head(5)\n",
    "                sample_preds = model.predict(input_example)\n",
    "                signature = infer_signature(input_example, sample_preds)\n",
    "                mlflow.sklearn.log_model(model, artifact_path='./artifacts/', signature=signature, input_example=input_example)\n",
    "            except Exception as e:\n",
    "                print(f\"Model logging failed: {e}\")\n",
    "                try:\n",
    "                    mlflow.sklearn.log_model(model, artifact_path='./artifacts/')\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Train Baseline Models\n",
    "# Generate seeds\n",
    "seeds = [random.randint(0, 10000) for _ in range(3)]\n",
    "print(f'Using seeds for testing: {seeds}')\n",
    "\n",
    "# Train baselines\n",
    "for seed in seeds:\n",
    "    train_and_log_baselines(X_iris, y_iris, dataset_name='iris', seed=seed)\n",
    "    if X_titanic is not None:\n",
    "        train_and_log_baselines(X_titanic, y_titanic, dataset_name='titanic', seed=seed)\n",
    "    train_and_log_baselines(X_wine, y_wine, dataset_name='wine', seed=seed)\n",
    "\n",
    "print(\"Baseline training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Model Registry - Train and Register Versions\n",
    "mlflow.set_experiment(\"Model Registry Demo\")\n",
    "model_name = \"IrisClassifier\"\n",
    "\n",
    "model_configs = [\n",
    "    {\"n_estimators\": 10, \"max_depth\": 3},\n",
    "    {\"n_estimators\": 50, \"max_depth\": 5},\n",
    "    {\"n_estimators\": 100, \"max_depth\": 10}\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_iris, y_iris, test_size=0.2, random_state=42)\n",
    "\n",
    "for i, config in enumerate(model_configs, 1):\n",
    "    with mlflow.start_run(run_name=f\"version_{i}\"):\n",
    "        model = RandomForestClassifier(n_estimators=config['n_estimators'], max_depth=config['max_depth'], random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        mlflow.log_params(config)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        \n",
    "        model_info = mlflow.sklearn.log_model(model, artifact_path=\"model\", registered_model_name=model_name)\n",
    "        print(f\"Registered {model_name} version {i} - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"Model versions registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Stage Transitions\n",
    "# Transition version 1 to Staging\n",
    "client.transition_model_version_stage(name=model_name, version=1, stage=\"Staging\")\n",
    "print(\"Version 1 moved to Staging\")\n",
    "\n",
    "# Transition version 2 to Staging (archive v1)\n",
    "client.transition_model_version_stage(name=model_name, version=2, stage=\"Staging\", archive_existing_versions=True)\n",
    "print(\"Version 2 moved to Staging (Version 1 archived)\")\n",
    "\n",
    "# Promote version 3 to Production\n",
    "client.transition_model_version_stage(name=model_name, version=3, stage=\"Production\")\n",
    "print(\"Version 3 moved to Production\")\n",
    "\n",
    "print(\"Stage transitions completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Create Directories and Load Production Model\n",
    "# Create directories\n",
    "os.makedirs('model_artifacts', exist_ok=True)\n",
    "os.makedirs('deployment', exist_ok=True)\n",
    "\n",
    "# Load production model\n",
    "model_uri = f\"models:/{model_name}/Production\"\n",
    "prod_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "y_pred = prod_model.predict(X_test)\n",
    "y_pred_proba = prod_model.predict_proba(X_test)\n",
    "\n",
    "print(\"Production model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Generate and Log Artifacts - Confusion Matrix\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title('Confusion Matrix - Production Model')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('model_artifacts/confusion_matrix.png', bbox_inches='tight', dpi=150)\n",
    "plt.close()\n",
    "mlflow.log_artifact('model_artifacts/confusion_matrix.png')\n",
    "\n",
    "print(\"Confusion matrix saved and logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Generate and Log Artifacts - Feature Importance\n",
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': iris.feature_names,\n",
    "    'importance': prod_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance - Production Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig('model_artifacts/feature_importance.png', bbox_inches='tight', dpi=150)\n",
    "plt.close()\n",
    "mlflow.log_artifact('model_artifacts/feature_importance.png')\n",
    "\n",
    "print(\"Feature importance plot saved and logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Generate and Log Artifacts - Classification Report and Metadata\n",
    "# Classification Report\n",
    "report = classification_report(y_test, y_pred, target_names=iris.target_names, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv('model_artifacts/classification_report.csv')\n",
    "mlflow.log_artifact('model_artifacts/classification_report.csv')\n",
    "\n",
    "# Model Metadata\n",
    "metadata = {\n",
    "    \"model_name\": model_name,\n",
    "    \"version\": \"3 (Production)\",\n",
    "    \"training_date\": datetime.now().isoformat(),\n",
    "    \"framework\": \"scikit-learn\",\n",
    "    \"algorithm\": \"RandomForestClassifier\",\n",
    "    \"metrics\": {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"f1_score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    },\n",
    "    \"feature_names\": iris.feature_names,\n",
    "    \"target_names\": iris.target_names.tolist(),\n",
    "    \"n_samples_train\": len(X_train),\n",
    "    \"n_samples_test\": len(X_test)\n",
    "}\n",
    "with open('model_artifacts/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "mlflow.log_artifact('model_artifacts/model_metadata.json')\n",
    "\n",
    "print(\"Classification report and metadata saved and logged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Batch Inference Test\n",
    "test_samples = pd.DataFrame({\n",
    "    'sepal length (cm)': [5.1, 6.7, 4.9],\n",
    "    'sepal width (cm)': [3.5, 3.0, 2.5],\n",
    "    'petal length (cm)': [1.4, 5.2, 4.5],\n",
    "    'petal width (cm)': [0.2, 2.3, 1.7]\n",
    "})\n",
    "\n",
    "predictions = prod_model.predict(test_samples)\n",
    "probabilities = prod_model.predict_proba(test_samples)\n",
    "\n",
    "print(\"Batch Inference Results:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (pred, probs) in enumerate(zip(predictions, probabilities)):\n",
    "    pred_name = iris.target_names[pred]\n",
    "    confidence = probs[pred] * 100\n",
    "    print(f\"Sample {i+1}: {pred_name} (confidence: {confidence:.1f}%)\")\n",
    "\n",
    "print(\"\\nBatch inference test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Create Serving Scripts\n",
    "# Serving instructions\n",
    "serving_instructions = \"\"\"\n",
    "# Model Serving Instructions\n",
    "# 1. Start MLflow server: mlflow server --host 127.0.0.1 --port 5000\n",
    "# 2. Serve model: mlflow models serve -m models:/IrisClassifier/Production -p 5001 --no-conda\n",
    "# 3. Test API: curl -X POST -H \"Content-Type: application/json\" \\\n",
    "#      --data '{\"dataframe_split\": {\"columns\": [\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"], \"data\": [[5.1, 3.5, 1.4, 0.2]]}}' \\\n",
    "#      http://127.0.0.1:5001/invocations\n",
    "\"\"\"\n",
    "\n",
    "with open('deployment/serving_instructions.txt', 'w') as f:\n",
    "    f.write(serving_instructions)\n",
    "\n",
    "# Batch inference script\n",
    "inference_script = \"\"\"import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "# Load production model\n",
    "model = mlflow.sklearn.load_model(\"models:/IrisClassifier/Production\")\n",
    "\n",
    "# Test data\n",
    "data = pd.DataFrame({\n",
    "    'sepal length (cm)': [5.1, 6.2, 5.9],\n",
    "    'sepal width (cm)': [3.5, 3.4, 3.0],\n",
    "    'petal length (cm)': [1.4, 5.4, 5.1],\n",
    "    'petal width (cm)': [0.2, 2.3, 1.8]\n",
    "})\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(data)\n",
    "probabilities = model.predict_proba(data)\n",
    "\n",
    "# Display results\n",
    "target_names = ['setosa', 'versicolor', 'virginica']\n",
    "for i, (pred, probs) in enumerate(zip(predictions, probabilities)):\n",
    "    pred_name = target_names[pred]\n",
    "    confidence = probs[pred] * 100\n",
    "    print(f\"Sample {i+1}: {pred_name} (confidence: {confidence:.1f}%)\")\n",
    "\"\"\"\n",
    "\n",
    "with open('deployment/batch_inference.py', 'w') as f:\n",
    "    f.write(inference_script)\n",
    "\n",
    "print(\"Serving scripts created in deployment/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has successfully:\n",
    "1. ✅ Trained baseline models and logged experiments\n",
    "2. ✅ Registered multiple model versions in MLflow Model Registry\n",
    "3. ✅ Performed stage transitions (Staging → Production)\n",
    "4. ✅ Generated and logged artifacts (plots, reports, metadata)\n",
    "5. ✅ Tested batch inference with the production model\n",
    "6. ✅ Created deployment scripts for model serving\n",
    "\n",
    "### Next Steps:\n",
    "- Visit http://127.0.0.1:5000 to explore the MLflow UI\n",
    "- Run the serving script: `mlflow models serve -m models:/IrisClassifier/Production -p 5001 --no-conda`\n",
    "- Test the REST API with curl commands\n",
    "- Check the generated artifacts in the `model_artifacts/` directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}